{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO37IzFvyrZ/0sloi97yNeA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aekanun2020/AdvancedStat/blob/main/prove_one_neuronRNN_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cNuo0Mxzm10",
        "outputId": "784a97ed-2b8f-4b3d-eaba-d4b222ea8742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters ของ RNN Cell:\n",
            "Weight W (input-to-hidden): 0.3116 - ใช้คำนวณอิทธิพลของ input ปัจจุบัน\n",
            "Weight U (hidden-to-hidden): -0.3960 - ใช้คำนวณอิทธิพลของ hidden state ก่อนหน้า\n",
            "\n",
            "สมการของ RNN Cell: h_t = tanh(W·x_t + U·h_{t-1})\n",
            "  โดย:\n",
            "    - h_t คือ hidden state ณ เวลา t\n",
            "    - x_t คือ input ณ เวลา t\n",
            "    - h_{t-1} คือ hidden state ก่อนหน้า\n",
            "    - W และ U คือ weight matrices ที่ใช้ในทุก time step (weight sharing)\n",
            "\n",
            "Input sequence:\n",
            "X_1 = 1.0\n",
            "X_2 = -0.7774999737739563\n",
            "X_3 = 0.2587999999523163\n",
            "\n",
            "Initial hidden state (h_0): 0.0\n",
            "\n",
            "การคำนวณ hidden state ที่แต่ละ time step:\n",
            "Time step 1:\n",
            "  W·x_1 = 0.3116 × 1.0 = 0.3116\n",
            "  U·h_0 = -0.3960 × 0.0 = -0.0000\n",
            "  h_1 = tanh(W·x_1 + U·h_0) = tanh(0.3116 + -0.0000) = tanh(0.3116) = 0.3019\n",
            "\n",
            "Time step 2:\n",
            "  W·x_2 = 0.3116 × -0.7774999737739563 = -0.2422\n",
            "  U·h_1 = -0.3960 × 0.30186378955841064 = -0.1195\n",
            "  h_2 = tanh(W·x_2 + U·h_1) = tanh(-0.2422 + -0.1195) = tanh(-0.3618) = -0.3468\n",
            "\n",
            "Time step 3:\n",
            "  W·x_3 = 0.3116 × 0.2587999999523163 = 0.0806\n",
            "  U·h_2 = -0.3960 × -0.3467714786529541 = 0.1373\n",
            "  h_3 = tanh(W·x_3 + U·h_2) = tanh(0.0806 + 0.1373) = tanh(0.2179) = 0.2146\n",
            "\n",
            "=== สรุปผลการทดลอง ===\n",
            "1. เราพบว่า RNN Cell ประกอบด้วย weights 2 ชุด:\n",
            "   - Weight W (input-to-hidden): 0.3116 - ใช้คำนวณผลกระทบของ input ปัจจุบัน\n",
            "   - Weight U (hidden-to-hidden): -0.3960 - ใช้คำนวณผลกระทบของ hidden state ก่อนหน้า\n",
            "\n",
            "2. RNN ใช้ weights เดียวกันในทุก time step (weight sharing)\n",
            "   - พิสูจน์ได้จากการคำนวณ h_1, h_2, และ h_3 โดยใช้ W และ U ค่าเดียวกัน\n",
            "   - นี่เป็นคุณสมบัติสำคัญที่ทำให้ RNN สามารถรับข้อมูลที่มีความยาวไม่แน่นอนได้\n",
            "\n",
            "3. ข้อมูลจากอดีตมีผลต่อการทำนายในปัจจุบัน\n",
            "   - h_0 มีผลต่อ h_1 ผ่านการคูณกับ U\n",
            "   - h_1 มีผลต่อ h_2 ผ่านการคูณกับ U\n",
            "   - h_2 มีผลต่อ h_3 ผ่านการคูณกับ U\n",
            "   - นี่คือกลไกที่ทำให้ RNN มี 'ความจำ' และเหมาะกับข้อมูลแบบลำดับ (sequence data)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.nn import Parameter\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# กำหนด seed เพื่อให้ผลลัพธ์คงที่\n",
        "torch.manual_seed(9)\n",
        "\n",
        "# สร้าง RNN Cell โดยมี input_size=1, hidden_size=1, และไม่มี bias\n",
        "rnn_a = torch.nn.RNNCell(input_size=1, hidden_size=1, bias=False)\n",
        "\n",
        "# แสดงค่า parameters ทั้งหมดใน RNN Cell พร้อมคำอธิบาย\n",
        "print(\"Parameters ของ RNN Cell:\")\n",
        "weights = list(rnn_a.parameters())\n",
        "w_ih = weights[0]  # Input-to-Hidden (Weight W)\n",
        "w_hh = weights[1]  # Hidden-to-Hidden (Weight U)\n",
        "print(f\"Weight W (input-to-hidden): {w_ih.item():.4f} - ใช้คำนวณอิทธิพลของ input ปัจจุบัน\")\n",
        "print(f\"Weight U (hidden-to-hidden): {w_hh.item():.4f} - ใช้คำนวณอิทธิพลของ hidden state ก่อนหน้า\")\n",
        "print(\"\\nสมการของ RNN Cell: h_t = tanh(W·x_t + U·h_{t-1})\")\n",
        "print(\"  โดย:\")\n",
        "print(\"    - h_t คือ hidden state ณ เวลา t\")\n",
        "print(\"    - x_t คือ input ณ เวลา t\")\n",
        "print(\"    - h_{t-1} คือ hidden state ก่อนหน้า\")\n",
        "print(\"    - W และ U คือ weight matrices ที่ใช้ในทุก time step (weight sharing)\")\n",
        "\n",
        "# สร้าง input sequence และ hidden state เริ่มต้น\n",
        "# ค่า input ที่ time step ที่ 1, 2, และ 3\n",
        "random_input = Variable(torch.FloatTensor(1, 3, 1).normal_(), requires_grad=False)\n",
        "random_input[0, 0, 0] = 1\n",
        "random_input[0, 1, 0] = -0.7775\n",
        "random_input[0, 2, 0] = 0.2588\n",
        "print(\"\\nInput sequence:\")\n",
        "print(f\"X_1 = {random_input[0, 0, 0].item()}\")\n",
        "print(f\"X_2 = {random_input[0, 1, 0].item()}\")\n",
        "print(f\"X_3 = {random_input[0, 2, 0].item()}\")\n",
        "\n",
        "# ค่า hidden state เริ่มต้น\n",
        "h0 = Variable(torch.zeros(1, 1), requires_grad=False)\n",
        "print(\"\\nInitial hidden state (h_0):\", h0.item())\n",
        "\n",
        "# คำนวณ hidden state ที่แต่ละ time step\n",
        "print(\"\\nการคำนวณ hidden state ที่แต่ละ time step:\")\n",
        "\n",
        "# Time step 1\n",
        "h1 = rnn_a(random_input[0, 0], h0)\n",
        "w_x1 = w_ih.item() * random_input[0, 0, 0].item()\n",
        "u_h0 = w_hh.item() * h0.item()\n",
        "print(\"Time step 1:\")\n",
        "print(f\"  W·x_1 = {w_ih.item():.4f} × {random_input[0, 0, 0].item()} = {w_x1:.4f}\")\n",
        "print(f\"  U·h_0 = {w_hh.item():.4f} × {h0.item()} = {u_h0:.4f}\")\n",
        "print(f\"  h_1 = tanh(W·x_1 + U·h_0) = tanh({w_x1:.4f} + {u_h0:.4f}) = tanh({w_x1 + u_h0:.4f}) = {h1.item():.4f}\")\n",
        "\n",
        "# Time step 2\n",
        "h2 = rnn_a(random_input[0, 1], h1)\n",
        "w_x2 = w_ih.item() * random_input[0, 1, 0].item()\n",
        "u_h1 = w_hh.item() * h1.item()\n",
        "print(\"\\nTime step 2:\")\n",
        "print(f\"  W·x_2 = {w_ih.item():.4f} × {random_input[0, 1, 0].item()} = {w_x2:.4f}\")\n",
        "print(f\"  U·h_1 = {w_hh.item():.4f} × {h1.item()} = {u_h1:.4f}\")\n",
        "print(f\"  h_2 = tanh(W·x_2 + U·h_1) = tanh({w_x2:.4f} + {u_h1:.4f}) = tanh({w_x2 + u_h1:.4f}) = {h2.item():.4f}\")\n",
        "\n",
        "# Time step 3\n",
        "h3 = rnn_a(random_input[0, 2], h2)\n",
        "w_x3 = w_ih.item() * random_input[0, 2, 0].item()\n",
        "u_h2 = w_hh.item() * h2.item()\n",
        "print(\"\\nTime step 3:\")\n",
        "print(f\"  W·x_3 = {w_ih.item():.4f} × {random_input[0, 2, 0].item()} = {w_x3:.4f}\")\n",
        "print(f\"  U·h_2 = {w_hh.item():.4f} × {h2.item()} = {u_h2:.4f}\")\n",
        "print(f\"  h_3 = tanh(W·x_3 + U·h_2) = tanh({w_x3:.4f} + {u_h2:.4f}) = tanh({w_x3 + u_h2:.4f}) = {h3.item():.4f}\")\n",
        "\n",
        "print(\"\\n=== สรุปผลการทดลอง ===\")\n",
        "print(\"1. เราพบว่า RNN Cell ประกอบด้วย weights 2 ชุด:\")\n",
        "print(f\"   - Weight W (input-to-hidden): {w_ih.item():.4f} - ใช้คำนวณผลกระทบของ input ปัจจุบัน\")\n",
        "print(f\"   - Weight U (hidden-to-hidden): {w_hh.item():.4f} - ใช้คำนวณผลกระทบของ hidden state ก่อนหน้า\")\n",
        "print(\"\\n2. RNN ใช้ weights เดียวกันในทุก time step (weight sharing)\")\n",
        "print(\"   - พิสูจน์ได้จากการคำนวณ h_1, h_2, และ h_3 โดยใช้ W และ U ค่าเดียวกัน\")\n",
        "print(\"   - นี่เป็นคุณสมบัติสำคัญที่ทำให้ RNN สามารถรับข้อมูลที่มีความยาวไม่แน่นอนได้\")\n",
        "print(\"\\n3. ข้อมูลจากอดีตมีผลต่อการทำนายในปัจจุบัน\")\n",
        "print(\"   - h_0 มีผลต่อ h_1 ผ่านการคูณกับ U\")\n",
        "print(\"   - h_1 มีผลต่อ h_2 ผ่านการคูณกับ U\")\n",
        "print(\"   - h_2 มีผลต่อ h_3 ผ่านการคูณกับ U\")\n",
        "print(\"   - นี่คือกลไกที่ทำให้ RNN มี 'ความจำ' และเหมาะกับข้อมูลแบบลำดับ (sequence data)\")"
      ]
    }
  ]
}