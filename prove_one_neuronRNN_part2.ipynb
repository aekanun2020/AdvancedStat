{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOX8A2iEElHsFDd6aYHsR0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aekanun2020/AdvancedStat/blob/main/prove_one_neuronRNN_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Parameter\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# กำหนด seed เพื่อให้ผลลัพธ์คงที่\n",
        "torch.manual_seed(9)\n",
        "\n",
        "# ==================== ส่วนที่ 1: การเตรียมโมเดลและข้อมูล ====================\n",
        "print(\"=\" * 60)\n",
        "print(\"ส่วนที่ 1: การเตรียมโมเดลและข้อมูล\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# สร้าง RNN Cell โดยมี input_size=1, hidden_size=1, และไม่มี bias\n",
        "rnn_model = torch.nn.RNNCell(input_size=1, hidden_size=1, bias=False)\n",
        "\n",
        "# Linear layer สำหรับแปลง hidden state เป็น output\n",
        "output_layer = torch.nn.Linear(1, 1, bias=False)\n",
        "\n",
        "# แสดงค่า parameters ทั้งหมดใน RNN Cell พร้อมคำอธิบาย\n",
        "weights = list(rnn_model.parameters())\n",
        "w_ih = weights[0]  # Input-to-Hidden (Weight W)\n",
        "w_hh = weights[1]  # Hidden-to-Hidden (Weight U)\n",
        "print(f\"Parameters เริ่มต้นของ RNN Cell:\")\n",
        "print(f\"Weight W (input-to-hidden): {w_ih.item():.4f}\")\n",
        "print(f\"Weight U (hidden-to-hidden): {w_hh.item():.4f}\")\n",
        "\n",
        "# กำหนดค่า V\n",
        "with torch.no_grad():\n",
        "    output_layer.weight.copy_(torch.tensor([[0.5]]))\n",
        "v_weight = output_layer.weight.item()\n",
        "print(f\"Weight V (hidden-to-output): {v_weight:.4f}\")\n",
        "\n",
        "# สร้างข้อมูลสำหรับ train: sine wave\n",
        "seq_length = 20\n",
        "time_steps = torch.linspace(0, 4*math.pi, seq_length)\n",
        "data = torch.sin(time_steps).unsqueeze(1)\n",
        "\n",
        "# แบ่งเป็น input และ target (เราต้องการทำนาย data[t+1] จาก data[t])\n",
        "x_train = data[:-1]  # ทุกค่ายกเว้นค่าสุดท้าย\n",
        "y_train = data[1:]   # ทุกค่ายกเว้นค่าแรก\n",
        "\n",
        "print(f\"\\nสร้างชุดข้อมูล sine wave ความยาว {seq_length} ค่า\")\n",
        "print(f\"จำนวน time steps ในชุดข้อมูล: {len(x_train)}\")\n",
        "print(f\"Shape ของ input (x): {x_train.shape}, target (y): {y_train.shape}\")\n",
        "\n",
        "print(\"\\nข้อมูล input และ target ทั้งหมด:\")\n",
        "print(\"  Time Step |    Input (x)    |   Target (y)   \")\n",
        "print(\"-\" * 50)\n",
        "for i in range(len(x_train)):\n",
        "    print(f\"     {i+1:2d}     |    {x_train[i].item():+.6f}    |    {y_train[i].item():+.6f}    \")\n",
        "\n",
        "# ==================== ส่วนที่ 2: การคำนวณก่อนการเทรน ====================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ส่วนที่ 2: การคำนวณก่อนการเทรน (Forward Pass แบบละเอียด)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# คำนวณ forward pass ก่อนการเทรน\n",
        "h = torch.zeros(1, 1)  # เริ่มต้นด้วย hidden state = 0\n",
        "\n",
        "print(\"\\nการคำนวณแบบละเอียดในแต่ละ time step ก่อนการเทรน:\")\n",
        "print(\"-\" * 90)\n",
        "print(\"Time Step |   Input (x)  |    h_{t-1}    |       W·x       |       U·h       |     h_t = tanh(W·x + U·h)     |      y_t = sigmoid(V·h_t)     |   Target   |    Error   \")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "total_squared_error = 0\n",
        "predictions = []\n",
        "\n",
        "for t in range(len(x_train)):\n",
        "    # รับค่า input และค่า target\n",
        "    x_t = x_train[t].unsqueeze(0)\n",
        "    y_target = y_train[t].item()\n",
        "\n",
        "    # คำนวณ forward pass ของ RNN Cell\n",
        "    Wx = w_ih.item() * x_t.item()\n",
        "    Uh = w_hh.item() * h.item()\n",
        "    next_h = torch.tanh(rnn_model.weight_ih * x_t + rnn_model.weight_hh * h)\n",
        "    y_pred = torch.sigmoid(output_layer(next_h))\n",
        "\n",
        "    # คำนวณ error\n",
        "    error = y_pred.item() - y_target\n",
        "    squared_error = error ** 2\n",
        "    total_squared_error += squared_error\n",
        "\n",
        "    # เก็บผลการทำนาย\n",
        "    predictions.append(y_pred.item())\n",
        "\n",
        "    # แสดงข้อมูลการคำนวณ\n",
        "    print(f\"    {t+1:2d}    | {x_t.item():+.6f} | {h.item():+.6f} | {Wx:+.6f} | {Uh:+.6f} | {next_h.item():+.6f} | {y_pred.item():+.6f} | {y_target:+.6f} | {error:+.6f}\")\n",
        "\n",
        "    # อัพเดท hidden state สำหรับ time step ถัดไป\n",
        "    h = next_h\n",
        "\n",
        "# คำนวณ MSE\n",
        "mse = total_squared_error / len(x_train)\n",
        "print(\"-\" * 90)\n",
        "print(f\"Mean Squared Error (MSE) ก่อนการเทรน: {mse:.6f}\")\n",
        "\n",
        "# ==================== ส่วนที่ 3: การเทรนโมเดล ====================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ส่วนที่ 3: การเทรนโมเดล RNN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# สร้างโมเดลใหม่เพื่อการเทรน (ใช้ค่าเริ่มต้นเดียวกับโมเดลก่อนหน้า)\n",
        "torch.manual_seed(9)\n",
        "rnn_train = torch.nn.RNNCell(input_size=1, hidden_size=1, bias=False)\n",
        "output_train = torch.nn.Linear(1, 1, bias=False)\n",
        "\n",
        "# กำหนดค่าเริ่มต้นให้เหมือนกับโมเดลก่อนหน้า\n",
        "with torch.no_grad():\n",
        "    rnn_train.weight_ih.copy_(w_ih)\n",
        "    rnn_train.weight_hh.copy_(w_hh)\n",
        "    output_train.weight.copy_(torch.tensor([[0.5]]))\n",
        "\n",
        "# สร้าง optimizer\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(list(rnn_train.parameters()) + list(output_train.parameters()), lr=learning_rate)\n",
        "print(f\"Optimizer: SGD with learning rate = {learning_rate}\")\n",
        "print(\"Loss function: Mean Squared Error (MSE)\")\n",
        "\n",
        "# จำนวน epochs\n",
        "num_epochs = 10\n",
        "print(f\"การเทรนจะใช้ {num_epochs} epochs กับข้อมูล {len(x_train)} time steps\")\n",
        "\n",
        "# เตรียมตัวแปรสำหรับเก็บประวัติ\n",
        "losses = []\n",
        "w_history = [rnn_train.weight_ih.item()]\n",
        "u_history = [rnn_train.weight_hh.item()]\n",
        "v_history = [output_train.weight.item()]\n",
        "\n",
        "# Train โมเดล\n",
        "print(\"\\nเริ่มการเทรน...\")\n",
        "for epoch in range(num_epochs):\n",
        "    # เริ่มต้นจาก hidden state เป็น 0\n",
        "    h = torch.zeros(1, 1)\n",
        "    h.requires_grad = True  # ต้องเก็บ gradient เพื่อการเทรน\n",
        "\n",
        "    # เก็บค่าทำนายทั้งหมด\n",
        "    predictions = []\n",
        "\n",
        "    # Forward pass ผ่านทุก time steps\n",
        "    for t in range(len(x_train)):\n",
        "        h = rnn_train(x_train[t].unsqueeze(0), h)\n",
        "        y_pred = output_train(h)\n",
        "        predictions.append(y_pred)\n",
        "\n",
        "    # รวมการทำนายทั้งหมดเป็น tensor เดียว\n",
        "    predictions = torch.cat(predictions)\n",
        "\n",
        "    # คำนวณ loss\n",
        "    loss = F.mse_loss(predictions, y_train)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Backward pass และการปรับค่า parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # เก็บค่า parameters หลังการปรับปรุง\n",
        "    w_history.append(rnn_train.weight_ih.item())\n",
        "    u_history.append(rnn_train.weight_hh.item())\n",
        "    v_history.append(output_train.weight.item())\n",
        "\n",
        "    # แสดงความคืบหน้า\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}\")\n",
        "    print(f\"  W: {rnn_train.weight_ih.item():.6f}, U: {rnn_train.weight_hh.item():.6f}, V: {output_train.weight.item():.6f}\")\n",
        "\n",
        "# แสดงการเปลี่ยนแปลงของ parameters\n",
        "print(\"\\nการเปลี่ยนแปลงของ parameters ในแต่ละ epoch:\")\n",
        "print(\"  Epoch |      W       |      U       |      V       |    Loss    \")\n",
        "print(\"-\" * 60)\n",
        "for i in range(num_epochs + 1):  # +1 เพราะรวมค่าเริ่มต้นก่อน epoch 1\n",
        "    if i == 0:\n",
        "        epoch_label = \"Initial\"\n",
        "    else:\n",
        "        epoch_label = f\"{i:5d}\"\n",
        "\n",
        "    loss_value = losses[i-1] if i > 0 else mse  # ใช้ MSE ก่อนเทรนสำหรับค่าเริ่มต้น\n",
        "    print(f\"  {epoch_label} | {w_history[i]:+.6f} | {u_history[i]:+.6f} | {v_history[i]:+.6f} | {loss_value:.6f}\")\n",
        "\n",
        "# ==================== ส่วนที่ 4: การคำนวณหลังการเทรน ====================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ส่วนที่ 4: การคำนวณหลังการเทรน (Forward Pass แบบละเอียด)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# คำนวณ forward pass หลังการเทรน\n",
        "h = torch.zeros(1, 1)  # เริ่มต้นด้วย hidden state = 0\n",
        "\n",
        "print(\"\\nการคำนวณแบบละเอียดในแต่ละ time step หลังการเทรน:\")\n",
        "print(\"-\" * 90)\n",
        "print(\"Time Step |   Input (x)  |    h_{t-1}    |       W·x       |       U·h       |     h_t = tanh(W·x + U·h)     |      y_t = sigmoid(V·h_t)     |   Target   |    Error   \")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "total_squared_error = 0\n",
        "final_predictions = []\n",
        "\n",
        "with torch.no_grad():  # ไม่ต้องคำนวณ gradient ในการทดสอบ\n",
        "    for t in range(len(x_train)):\n",
        "        # รับค่า input และค่า target\n",
        "        x_t = x_train[t].unsqueeze(0)\n",
        "        y_target = y_train[t].item()\n",
        "\n",
        "        # คำนวณ forward pass ของ RNN Cell\n",
        "        Wx = rnn_train.weight_ih.item() * x_t.item()\n",
        "        Uh = rnn_train.weight_hh.item() * h.item()\n",
        "        next_h = torch.tanh(rnn_train.weight_ih * x_t + rnn_train.weight_hh * h)\n",
        "        y_pred = torch.sigmoid(output_train(next_h))\n",
        "\n",
        "        # คำนวณ error\n",
        "        error = y_pred.item() - y_target\n",
        "        squared_error = error ** 2\n",
        "        total_squared_error += squared_error\n",
        "\n",
        "        # เก็บผลการทำนาย\n",
        "        final_predictions.append(y_pred.item())\n",
        "\n",
        "        # แสดงข้อมูลการคำนวณ\n",
        "        print(f\"    {t+1:2d}    | {x_t.item():+.6f} | {h.item():+.6f} | {Wx:+.6f} | {Uh:+.6f} | {next_h.item():+.6f} | {y_pred.item():+.6f} | {y_target:+.6f} | {error:+.6f}\")\n",
        "\n",
        "        # อัพเดท hidden state สำหรับ time step ถัดไป\n",
        "        h = next_h\n",
        "\n",
        "# คำนวณ MSE\n",
        "final_mse = total_squared_error / len(x_train)\n",
        "print(\"-\" * 90)\n",
        "print(f\"Mean Squared Error (MSE) หลังการเทรน: {final_mse:.6f}\")\n",
        "print(f\"เปรียบเทียบกับ MSE ก่อนการเทรน: {mse:.6f}\")\n",
        "improvement = ((mse - final_mse) / mse) * 100\n",
        "print(f\"การเทรนช่วยลด MSE ลง: {improvement:.2f}%\")\n",
        "\n",
        "# ==================== ส่วนที่ 5: สรุปการเปลี่ยนแปลงของ Parameters ====================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ส่วนที่ 5: สรุปการเปลี่ยนแปลงของ Parameters\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"Parameters ก่อนการเทรน:\")\n",
        "print(f\"  W: {w_ih.item():.6f}\")\n",
        "print(f\"  U: {w_hh.item():.6f}\")\n",
        "print(f\"  V: {v_weight:.6f}\")\n",
        "\n",
        "print(\"\\nParameters หลังการเทรน:\")\n",
        "print(f\"  W: {rnn_train.weight_ih.item():.6f}\")\n",
        "print(f\"  U: {rnn_train.weight_hh.item():.6f}\")\n",
        "print(f\"  V: {output_train.weight.item():.6f}\")\n",
        "\n",
        "w_change = ((rnn_train.weight_ih.item() - w_ih.item()) / w_ih.item()) * 100\n",
        "u_change = ((rnn_train.weight_hh.item() - w_hh.item()) / w_hh.item()) * 100\n",
        "v_change = ((output_train.weight.item() - v_weight) / v_weight) * 100\n",
        "\n",
        "print(\"\\nการเปลี่ยนแปลงของ parameters (%):\")\n",
        "print(f\"  W: {w_change:+.2f}%\")\n",
        "print(f\"  U: {u_change:+.2f}%\")\n",
        "print(f\"  V: {v_change:+.2f}%\")\n",
        "\n",
        "# ==================== ส่วนที่ 6: บทบาทของ y ในการเทรน ====================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ส่วนที่ 6: บทบาทของ y ในการเทรน\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"1. การคำนวณค่า y ในแต่ละ time step:\")\n",
        "print(\"   - ในแต่ละ time step, RNN คำนวณ hidden state (h_t) และ output (y_t)\")\n",
        "print(\"   - y_t = sigmoid(V·h_t) เป็นผลลัพธ์ที่โมเดลใช้ในการทำนาย\")\n",
        "print(\"   - ในตัวอย่างนี้ เรามี 19 time steps จึงมีการคำนวณ y ทั้งหมด 19 ค่าในแต่ละ epoch\")\n",
        "\n",
        "print(\"\\n2. บทบาทของ y ในการคำนวณ loss:\")\n",
        "print(\"   - ค่า y ในแต่ละ time step ถูกนำไปเปรียบเทียบกับค่าเป้าหมาย (target)\")\n",
        "print(\"   - ความแตกต่างระหว่าง y กับ target คือ error ซึ่งใช้ในการคำนวณ loss\")\n",
        "print(\"   - loss = MSE = (1/n) * Σ(y - target)²\")\n",
        "print(\"   - จะเห็นว่า loss ลดลงจาก {:.6f} เป็น {:.6f} หลังการเทรน\".format(mse, final_mse))\n",
        "\n",
        "print(\"\\n3. บทบาทของ y ในการคำนวณ gradient และปรับปรุง parameters:\")\n",
        "print(\"   - ค่า gradient ของ loss เทียบกับ y (∂loss/∂y) ถูกคำนวณในขั้นตอน backward\")\n",
        "print(\"   - จากนั้น gradient จะถูกส่งผ่านไปยัง parameters (W, U, V) ตามกฎลูกโซ่\")\n",
        "print(\"   - ในแต่ละ epoch, parameters ถูกปรับด้วย gradient และ learning rate\")\n",
        "print(\"   - การปรับ parameters ทำให้ y ใกล้เคียงกับ target มากขึ้นเรื่อยๆ\")\n",
        "\n",
        "print(\"\\n4. ความสัมพันธ์ระหว่าง h กับ y:\")\n",
        "print(\"   - hidden state (h) เก็บข้อมูลจากทั้ง input ปัจจุบันและข้อมูลในอดีต\")\n",
        "print(\"   - output (y) แปลงข้อมูลจาก hidden state ให้อยู่ในรูปแบบที่เหมาะสมกับงาน\")\n",
        "print(\"   - ในตัวอย่างนี้ sigmoid ถูกใช้เพื่อแปลง h เป็น y ที่อยู่ในช่วง (0, 1)\")\n",
        "print(\"   - การปรับปรุง W, U จะส่งผลต่อ h และในที่สุดส่งผลต่อ y\")\n",
        "print(\"   - การปรับปรุง V จะส่งผลโดยตรงต่อการแปลง h เป็น y\")\n",
        "\n",
        "print(\"\\n5. สรุปความสำคัญของ y:\")\n",
        "print(\"   - y เป็นตัวเชื่อมระหว่างโมเดลกับข้อมูลจริง\")\n",
        "print(\"   - y ใช้ในการประเมินประสิทธิภาพของโมเดลผ่าน loss function\")\n",
        "print(\"   - y ใช้ในการปรับปรุงโมเดลผ่านกระบวนการ backpropagation\")\n",
        "print(\"   - โดยสรุป: ถ้าไม่มี y เราจะไม่สามารถเทรนโมเดล RNN ได้เลย\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWhFxNmS5YOu",
        "outputId": "6dbe0885-721c-40fd-c796-eaf70b5666df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ส่วนที่ 1: การเตรียมโมเดลและข้อมูล\n",
            "============================================================\n",
            "Parameters เริ่มต้นของ RNN Cell:\n",
            "Weight W (input-to-hidden): 0.3116\n",
            "Weight U (hidden-to-hidden): -0.3960\n",
            "Weight V (hidden-to-output): 0.5000\n",
            "\n",
            "สร้างชุดข้อมูล sine wave ความยาว 20 ค่า\n",
            "จำนวน time steps ในชุดข้อมูล: 19\n",
            "Shape ของ input (x): torch.Size([19, 1]), target (y): torch.Size([19, 1])\n",
            "\n",
            "ข้อมูล input และ target ทั้งหมด:\n",
            "  Time Step |    Input (x)    |   Target (y)   \n",
            "--------------------------------------------------\n",
            "      1     |    +0.000000    |    +0.614213    \n",
            "      2     |    +0.614213    |    +0.969400    \n",
            "      3     |    +0.969400    |    +0.915773    \n",
            "      4     |    +0.915773    |    +0.475947    \n",
            "      5     |    +0.475947    |    -0.164595    \n",
            "      6     |    -0.164595    |    -0.735724    \n",
            "      7     |    -0.735724    |    -0.996584    \n",
            "      8     |    -0.996584    |    -0.837166    \n",
            "      9     |    -0.837166    |    -0.324700    \n",
            "     10     |    -0.324700    |    +0.324700    \n",
            "     11     |    +0.324700    |    +0.837167    \n",
            "     12     |    +0.837167    |    +0.996584    \n",
            "     13     |    +0.996584    |    +0.735724    \n",
            "     14     |    +0.735724    |    +0.164594    \n",
            "     15     |    +0.164594    |    -0.475948    \n",
            "     16     |    -0.475948    |    -0.915773    \n",
            "     17     |    -0.915773    |    -0.969400    \n",
            "     18     |    -0.969400    |    -0.614212    \n",
            "     19     |    -0.614212    |    +0.000000    \n",
            "\n",
            "============================================================\n",
            "ส่วนที่ 2: การคำนวณก่อนการเทรน (Forward Pass แบบละเอียด)\n",
            "============================================================\n",
            "\n",
            "การคำนวณแบบละเอียดในแต่ละ time step ก่อนการเทรน:\n",
            "------------------------------------------------------------------------------------------\n",
            "Time Step |   Input (x)  |    h_{t-1}    |       W·x       |       U·h       |     h_t = tanh(W·x + U·h)     |      y_t = sigmoid(V·h_t)     |   Target   |    Error   \n",
            "------------------------------------------------------------------------------------------\n",
            "     1    | +0.000000 | +0.000000 | +0.000000 | -0.000000 | +0.000000 | +0.500000 | +0.614213 | -0.114213\n",
            "     2    | +0.614213 | +0.000000 | +0.191370 | -0.000000 | +0.189067 | +0.523616 | +0.969400 | -0.445784\n",
            "     3    | +0.969400 | +0.189067 | +0.302035 | -0.074862 | +0.223344 | +0.527889 | +0.915773 | -0.387884\n",
            "     4    | +0.915773 | +0.223344 | +0.285327 | -0.088434 | +0.194387 | +0.524279 | +0.475947 | +0.048332\n",
            "     5    | +0.475947 | +0.194387 | +0.148290 | -0.076968 | +0.071201 | +0.508899 | -0.164595 | +0.673494\n",
            "     6    | -0.164595 | +0.071201 | -0.051283 | -0.028192 | -0.079308 | +0.490088 | -0.735724 | +1.225812\n",
            "     7    | -0.735724 | -0.079308 | -0.229229 | +0.031402 | -0.195285 | +0.475609 | -0.996584 | +1.472193\n",
            "     8    | -0.996584 | -0.195285 | -0.310505 | +0.077324 | -0.229044 | +0.471401 | -0.837166 | +1.308567\n",
            "     9    | -0.837166 | -0.229044 | -0.260835 | +0.090691 | -0.168521 | +0.478947 | -0.324700 | +0.803647\n",
            "    10    | -0.324700 | -0.168521 | -0.101166 | +0.066727 | -0.034426 | +0.495697 | +0.324700 | +0.170997\n",
            "    11    | +0.324700 | -0.034426 | +0.101166 | +0.013631 | +0.114296 | +0.514283 | +0.837167 | -0.322884\n",
            "    12    | +0.837167 | +0.114296 | +0.260835 | -0.045256 | +0.212300 | +0.526513 | +0.996584 | -0.470072\n",
            "    13    | +0.996584 | +0.212300 | +0.310505 | -0.084061 | +0.222651 | +0.527803 | +0.735724 | -0.207921\n",
            "    14    | +0.735724 | +0.222651 | +0.229229 | -0.088160 | +0.140141 | +0.517510 | +0.164594 | +0.352917\n",
            "    15    | +0.164594 | +0.140141 | +0.051282 | -0.055489 | -0.004207 | +0.499474 | -0.475948 | +0.975422\n",
            "    16    | -0.475948 | -0.004207 | -0.148291 | +0.001666 | -0.145583 | +0.481810 | -0.915773 | +1.397583\n",
            "    17    | -0.915773 | -0.145583 | -0.285327 | +0.057644 | -0.223828 | +0.472051 | -0.969400 | +1.441451\n",
            "    18    | -0.969400 | -0.223828 | -0.302035 | +0.088626 | -0.210227 | +0.473746 | -0.614212 | +1.087958\n",
            "    19    | -0.614212 | -0.210227 | -0.191369 | +0.083241 | -0.107709 | +0.486540 | +0.000000 | +0.486539\n",
            "------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) ก่อนการเทรน: 0.724810\n",
            "\n",
            "============================================================\n",
            "ส่วนที่ 3: การเทรนโมเดล RNN\n",
            "============================================================\n",
            "Optimizer: SGD with learning rate = 0.1\n",
            "Loss function: Mean Squared Error (MSE)\n",
            "การเทรนจะใช้ 10 epochs กับข้อมูล 19 time steps\n",
            "\n",
            "เริ่มการเทรน...\n",
            "Epoch 1/10, Loss: 0.404996\n",
            "  W: 0.339270, U: -0.392047, V: 0.517660\n",
            "Epoch 2/10, Loss: 0.393897\n",
            "  W: 0.367253, U: -0.387811, V: 0.536509\n",
            "Epoch 3/10, Loss: 0.382186\n",
            "  W: 0.395476, U: -0.383263, V: 0.556465\n",
            "Epoch 4/10, Loss: 0.369895\n",
            "  W: 0.423877, U: -0.378430, V: 0.577433\n",
            "Epoch 5/10, Loss: 0.357078\n",
            "  W: 0.452380, U: -0.373348, V: 0.599305\n",
            "Epoch 6/10, Loss: 0.343814\n",
            "  W: 0.480893, U: -0.368066, V: 0.621960\n",
            "Epoch 7/10, Loss: 0.330203\n",
            "  W: 0.509309, U: -0.362642, V: 0.645261\n",
            "Epoch 8/10, Loss: 0.316368\n",
            "  W: 0.537512, U: -0.357148, V: 0.669064\n",
            "Epoch 9/10, Loss: 0.302447\n",
            "  W: 0.565376, U: -0.351662, V: 0.693212\n",
            "Epoch 10/10, Loss: 0.288589\n",
            "  W: 0.592772, U: -0.346276, V: 0.717545\n",
            "\n",
            "การเปลี่ยนแปลงของ parameters ในแต่ละ epoch:\n",
            "  Epoch |      W       |      U       |      V       |    Loss    \n",
            "------------------------------------------------------------\n",
            "  Initial | +0.311569 | -0.395955 | +0.500000 | 0.724810\n",
            "      1 | +0.339270 | -0.392047 | +0.517660 | 0.404996\n",
            "      2 | +0.367253 | -0.387811 | +0.536509 | 0.393897\n",
            "      3 | +0.395476 | -0.383263 | +0.556465 | 0.382186\n",
            "      4 | +0.423877 | -0.378430 | +0.577433 | 0.369895\n",
            "      5 | +0.452380 | -0.373348 | +0.599305 | 0.357078\n",
            "      6 | +0.480893 | -0.368066 | +0.621960 | 0.343814\n",
            "      7 | +0.509309 | -0.362642 | +0.645261 | 0.330203\n",
            "      8 | +0.537512 | -0.357148 | +0.669064 | 0.316368\n",
            "      9 | +0.565376 | -0.351662 | +0.693212 | 0.302447\n",
            "     10 | +0.592772 | -0.346276 | +0.717545 | 0.288589\n",
            "\n",
            "============================================================\n",
            "ส่วนที่ 4: การคำนวณหลังการเทรน (Forward Pass แบบละเอียด)\n",
            "============================================================\n",
            "\n",
            "การคำนวณแบบละเอียดในแต่ละ time step หลังการเทรน:\n",
            "------------------------------------------------------------------------------------------\n",
            "Time Step |   Input (x)  |    h_{t-1}    |       W·x       |       U·h       |     h_t = tanh(W·x + U·h)     |      y_t = sigmoid(V·h_t)     |   Target   |    Error   \n",
            "------------------------------------------------------------------------------------------\n",
            "     1    | +0.000000 | +0.000000 | +0.000000 | -0.000000 | +0.000000 | +0.500000 | +0.614213 | -0.114213\n",
            "     2    | +0.614213 | +0.000000 | +0.364088 | -0.000000 | +0.348810 | +0.562247 | +0.969400 | -0.407153\n",
            "     3    | +0.969400 | +0.348810 | +0.574633 | -0.120784 | +0.425058 | +0.575664 | +0.915773 | -0.340109\n",
            "     4    | +0.915773 | +0.425058 | +0.542844 | -0.147187 | +0.376227 | +0.567083 | +0.475947 | +0.091136\n",
            "     5    | +0.475947 | +0.376227 | +0.282128 | -0.130278 | +0.150693 | +0.527006 | -0.164595 | +0.691601\n",
            "     6    | -0.164595 | +0.150693 | -0.097567 | -0.052181 | -0.148639 | +0.473361 | -0.735724 | +1.209085\n",
            "     7    | -0.735724 | -0.148639 | -0.436116 | +0.051470 | -0.366736 | +0.434590 | -0.996584 | +1.431174\n",
            "     8    | -0.996584 | -0.366736 | -0.590747 | +0.126992 | -0.433140 | +0.422920 | -0.837166 | +1.260087\n",
            "     9    | -0.837166 | -0.433140 | -0.496249 | +0.149986 | -0.333057 | +0.440537 | -0.324700 | +0.765236\n",
            "    10    | -0.324700 | -0.333057 | -0.192473 | +0.115329 | -0.076991 | +0.486192 | +0.324700 | +0.161493\n",
            "    11    | +0.324700 | -0.076991 | +0.192473 | +0.026660 | +0.215691 | +0.538615 | +0.837167 | -0.298552\n",
            "    12    | +0.837167 | +0.215691 | +0.496249 | -0.074689 | +0.398244 | +0.570957 | +0.996584 | -0.425627\n",
            "    13    | +0.996584 | +0.398244 | +0.590747 | -0.137902 | +0.424235 | +0.575520 | +0.735724 | -0.160204\n",
            "    14    | +0.735724 | +0.424235 | +0.436116 | -0.146902 | +0.281411 | +0.550310 | +0.164594 | +0.385717\n",
            "    15    | +0.164594 | +0.281411 | +0.097567 | -0.097446 | +0.000121 | +0.500022 | -0.475948 | +0.975969\n",
            "    16    | -0.475948 | +0.000121 | -0.282128 | -0.000042 | -0.274912 | +0.450844 | -0.915773 | +1.366617\n",
            "    17    | -0.915773 | -0.274912 | -0.542844 | +0.095195 | -0.419965 | +0.425229 | -0.969400 | +1.394629\n",
            "    18    | -0.969400 | -0.419965 | -0.574633 | +0.145423 | -0.404660 | +0.427915 | -0.614212 | +1.042127\n",
            "    19    | -0.614212 | -0.404660 | -0.364087 | +0.140124 | -0.220292 | +0.460565 | +0.000000 | +0.460564\n",
            "------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) หลังการเทรน: 0.684146\n",
            "เปรียบเทียบกับ MSE ก่อนการเทรน: 0.724810\n",
            "การเทรนช่วยลด MSE ลง: 5.61%\n",
            "\n",
            "============================================================\n",
            "ส่วนที่ 5: สรุปการเปลี่ยนแปลงของ Parameters\n",
            "============================================================\n",
            "Parameters ก่อนการเทรน:\n",
            "  W: 0.311569\n",
            "  U: -0.395955\n",
            "  V: 0.500000\n",
            "\n",
            "Parameters หลังการเทรน:\n",
            "  W: 0.592772\n",
            "  U: -0.346276\n",
            "  V: 0.717545\n",
            "\n",
            "การเปลี่ยนแปลงของ parameters (%):\n",
            "  W: +90.25%\n",
            "  U: -12.55%\n",
            "  V: +43.51%\n",
            "\n",
            "============================================================\n",
            "ส่วนที่ 6: บทบาทของ y ในการเทรน\n",
            "============================================================\n",
            "1. การคำนวณค่า y ในแต่ละ time step:\n",
            "   - ในแต่ละ time step, RNN คำนวณ hidden state (h_t) และ output (y_t)\n",
            "   - y_t = sigmoid(V·h_t) เป็นผลลัพธ์ที่โมเดลใช้ในการทำนาย\n",
            "   - ในตัวอย่างนี้ เรามี 19 time steps จึงมีการคำนวณ y ทั้งหมด 19 ค่าในแต่ละ epoch\n",
            "\n",
            "2. บทบาทของ y ในการคำนวณ loss:\n",
            "   - ค่า y ในแต่ละ time step ถูกนำไปเปรียบเทียบกับค่าเป้าหมาย (target)\n",
            "   - ความแตกต่างระหว่าง y กับ target คือ error ซึ่งใช้ในการคำนวณ loss\n",
            "   - loss = MSE = (1/n) * Σ(y - target)²\n",
            "   - จะเห็นว่า loss ลดลงจาก 0.724810 เป็น 0.684146 หลังการเทรน\n",
            "\n",
            "3. บทบาทของ y ในการคำนวณ gradient และปรับปรุง parameters:\n",
            "   - ค่า gradient ของ loss เทียบกับ y (∂loss/∂y) ถูกคำนวณในขั้นตอน backward\n",
            "   - จากนั้น gradient จะถูกส่งผ่านไปยัง parameters (W, U, V) ตามกฎลูกโซ่\n",
            "   - ในแต่ละ epoch, parameters ถูกปรับด้วย gradient และ learning rate\n",
            "   - การปรับ parameters ทำให้ y ใกล้เคียงกับ target มากขึ้นเรื่อยๆ\n",
            "\n",
            "4. ความสัมพันธ์ระหว่าง h กับ y:\n",
            "   - hidden state (h) เก็บข้อมูลจากทั้ง input ปัจจุบันและข้อมูลในอดีต\n",
            "   - output (y) แปลงข้อมูลจาก hidden state ให้อยู่ในรูปแบบที่เหมาะสมกับงาน\n",
            "   - ในตัวอย่างนี้ sigmoid ถูกใช้เพื่อแปลง h เป็น y ที่อยู่ในช่วง (0, 1)\n",
            "   - การปรับปรุง W, U จะส่งผลต่อ h และในที่สุดส่งผลต่อ y\n",
            "   - การปรับปรุง V จะส่งผลโดยตรงต่อการแปลง h เป็น y\n",
            "\n",
            "5. สรุปความสำคัญของ y:\n",
            "   - y เป็นตัวเชื่อมระหว่างโมเดลกับข้อมูลจริง\n",
            "   - y ใช้ในการประเมินประสิทธิภาพของโมเดลผ่าน loss function\n",
            "   - y ใช้ในการปรับปรุงโมเดลผ่านกระบวนการ backpropagation\n",
            "   - โดยสรุป: ถ้าไม่มี y เราจะไม่สามารถเทรนโมเดล RNN ได้เลย\n"
          ]
        }
      ]
    }
  ]
}